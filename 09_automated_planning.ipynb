{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"09_automated_planning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/9KasQCR5zRUmU2AAoWKd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"E-NK-AWOjzif"},"source":["# **Automated Planning**\n","It's an important problem solving activity which consists in synthesizing a **sequence of actions** performed by an agent, that leads from an initial state of the world to a given target state (**goal**).\n","It's **semi-decidable** so it's really a difficult problem for computers.\n","\n","Given:\n","* An initial state;\n","* A set of action;\n","* A state to achieve.\n","\n","Find:\n","* A **plan**: partially or totally ordered set of actions needed to achieve the goal from the initial state.\n","\n","An **automated planner** is an intelligent agent that operates in a certain domain described by:\n","* A representation of the **initial state** and the **goal**;\n","* A formal description of the executable actions.\n","\n","It dynamically define the plan.\n","\n","# Domain theory\n","A planner relies on **formal description** of the executable actions.\n","Each action is identified by a name and it's modeled through:\n","* **Preconditions**: that must hold to ensure that the action can be executed;\n","* **Postconditions**: represents the effects of the action.\n","\n","# Planning vs. Execution\n","Planning is a solving process for deciding the steps that solve a planning problem, is:\n","* **Non-decomposable**: there can be interaction between subgoals;\n","* **Reversible**: choices made during plan generation are backtrackable because the planning activity is *offline*;\n","* The effects of the actions are deterministic.\n","\n","A planner is:\n","* **Complete**: if always finds a plan when it exists;\n","* **Correct**: if solution found leads from the initial state to the goal.\n","\n","The execution is the implementation of the plan, is:\n","* **Irreversible**: often the execution of an action isn't backtrackable, the activity is *online*;\n","* **Non-deterministic**: can have different effects from the expected ones. Working in real world **pertains uncertainty**. In principle we can find a recovery plan."]},{"cell_type":"markdown","metadata":{"id":"NQi2HdM1LVnQ"},"source":["# Generative planning\r\n","It's an **offline** planning that **produces the whole plan before execution**.\r\n","Works on a snapshot of the current state.\r\n","It's based on some assumptions:\r\n","* **Atomic time**: actions are uninterruptible;\r\n","* **Determinism**;\r\n","* **Closed world assumption**: the initial state is apriori **fully known** and the plan execution is the **only cause of changing** in the world (no other agents).\r\n","\r\n","It's opposed to reactive planning."]},{"cell_type":"markdown","metadata":{"id":"WFFClXJcr6pr"},"source":["# Planning as search\n","It's a general purpose algorithm that may be very expensive computationally.\n","Planning can be seen as a forward search activity (from initial state to the goal).\n","There are many different views of planning as search where states and operators change\n","\n","Type | **States** | **Operators**\n","--- | --- | ---\n","Theorem proving | Set of propositions | Deductive rules\n","Search in state space | Set of propositions | Actions\n","Search in plan space | Partial plans | Plan refinement or completion moves\n","\n","# Linear planning \n","A linear planner formulates the planning problem as a search in the state space using classical search strategies. Provides an order.\n","The algorithm could proceed:\n","* **Forward**: starts from the initial state and proceeds until it finds a state that is a **superset** of the goal (a set where a subset representing the goal exists). Not really computational affordable, needed pruning or heuristics to guide the search.\n","* **Backward**: starts form the goal and proceeds until it finds a state that is a **subset** of the initial state. Based on **goal regression**, a mechanism to reduce a goal in subgoals during search by applying rules (actions).\n","\n","\n","**Goal regression**: used in backward search, it's a mechanism to reduce a goal in subgoals during search by applying rules (actions). Effects of actions can be positive or negative: add-list and delete-list.\n","Given a goal $G$ and a rule $R$, regression of $G$ through $R$ is:\n","* `Regr[G,R] = true` if $G \\in \\text{Add-list}$;\n","* `Regr[G,R] = false` if $G \\in \\text{Delete-list}$;\n","* `Regr[G,R] = G` otherwise."]},{"cell_type":"markdown","metadata":{"id":"e_sib_7_ASso"},"source":["# Deductive planning\n","Deductive planning uses first order logic for representing states, goal and actions (clauses) and generates a plan as a theorem proof.\n","There exists two formulation:\n","* **Green's formulation**, easier and more general purpose;\n","* **Kowalsky's formulation**, way stronger.\n","\n","Note: $a \\to b$ can be transformed into $\\neg a \\lor b$ (**Horn clauses**).\n","\n","# Situation calculus\n","* **Situation**: world snapshot describing properties (**fluents**) that hold in a given state $s$;\n","* **Actions**: define which fluents are true as a consequence of an action (**clauses**).\n","\n","**Frame problem**: all properties true before the action must be true also after if they're untouched by the action.\n","\n","# Green formulation\n","Green uses situation calculus to build a planning based on **logic resolution and unification**.\n","He finds a proof of a formula containing a state variable.\n","At the end of the proof the state variable will be instantiated to the plan to reach the objective.\n","Has high expressivity and can describe complex problems. Suffer the **frame problem** since we have to **explicitly list all fluents that change and those that do not change after a state transition**. It's not very efficient.\n","\n","# Kowalsky formulation\n","We use a:\n","* Predicate $\\text{holds}(\\text{rel}, s/a)$ to describe all the relation rel that are true in a given state $s$ or made true by the execution of an action $A$;\n","* Predicate $\\text{poss}(s)$ that indicate if a state is possible (reachable);\n","* Predicate $\\text{pact}(A,s)$ that indicate that it is possible to execute an action $A$ in a state $s$ (precondition of $A$ are true in $s$).\n","\n","**If** a state $s$ is possible **and** the preconditions of an action $A$ are satisfied in that state **then** it's possible the state produced after the execution of $A$: $$\\text{poss}(s) \\land \\text{pact}(A,s) \\to \\text{poss}(\\text{do}(A,s))$$\n","\n","In this way we need one **frame assertion** per action.\n","We can use prolog resolution for create plans."]},{"cell_type":"markdown","metadata":{"id":"NTq_gjC4k_QC"},"source":["# STRIPS (Standford Research Institute Problem Solver)\n","It's an algorithm for plan construction. \n","Has a specific language for the actions, an easier syntax than the situation calculus so is less expressive yet more efficient.\n","* **State representation**: fluent that are true in a given state;\n","* **Goal representation**: fluent that are true in the goal state. There can be variables.;\n","* **Action representation**: comes with three lists\n","> * **Preconditions**: fluents that should be true for applying the move;\n","  * **Delete-list**: fluents that become false after the move;\n","  * **Add-list**: fluents that become true after the move.\n","  * Sometimes add-list and delete-list are glued together in an effect-list with positive and negative axioms.\n","\n","The frame problem is solved with the **strip assumption**: everything which is not in the add-list and delete-list is unchanged.\n","\n","# The algorithm\n","It's a linear planner based on backward search (goal regression: from goal to initial state). \n","Initial state is fully known (close world assumption).\n","There are two data structures:\n","* **Goal stack**: LIFO stack, I can only remove the top. It proceeds backwards;\n","* **Description of the current state**: it proceeds forward.\n","> **Algorithm**:\n","  1. Initialize the stack with the goal to reach;\n","  1. While the stack isn't empty:\n","  * If $\\text{top}(\\text{stack})=A$ and $A\\theta \\subseteq S$ (can be unified with the initial state), then $\\text{pop}(A)$ and execute substitution $\\theta$ (unification in general) on the stack;\n","  * Else, if $\\text{top}(\\text{stack})=a$, then select a rule $R$ with $a \\in \\text{Add-list}(R)$, $\\text{pop}(A)$, $\\text{push}(R)$, $\\text{push}(\\text{Precond}(R)$);\n","  * Else, if $\\text{top}(\\text{stack})=a_1 \\land \\dots \\land a_n $ (actions emerge from the stack), then $\\text{push}(a_1)$, $\\text{push}(a_2)$, $\\dots$, $\\text{push}(a_n)$;\n","  * Else, if $\\text{top}(\\text{stack})=R$, then $\\text{pop}(R)$ and apply $R$ on $S$.\n","\n","The problem is divided into sungoals which might interact (not indipendent).\n","There are many possible goal ordering, reaching a goal may destroy another one.\n","At each goal we select one subgoal from the stack.\n","When we have a set of action that reach a goal, we execute them on the state that proceeds forward.\n","The process goes until the stack is empty.\n","When at the top of the stack we find an and of goals, we need to check that this is still satisfied in the current state before removing it, if it's not we have to reinsert it and change the order.\n","\n","There are some pittfalls:\n","* It's a **very large search space**: the choice of ordering is not deterministic and more action are applicable to reduce a goal. A solution can be use heuristic startegies to select the goal and the action (means-ends analysis, find the most significant difference between the state and the goal and reduce that);\n","* The **goals are interacting**: a complete solution is try all possible orderings of goals and subgoals. In practice they're solved indipendently and verified afterward: if the conjucton isn't true, change ordering;\n","* **Sussman anomaly**: it happens when we can choose between two possible orderings, but one them destroy the previous achieved goal, so we need to backtrack and try the other ordering (not much efficient)."]},{"cell_type":"markdown","metadata":{"id":"YZ8z2nKZAOWK"},"source":["# Non-linear planning (partial order planning)\n","Non-linear planners are search algorithm that generate a plan as a search problem in the space of plans. In the search tree: \n","* Each **node** is a partial plan;\n","* **Operators** are plan refinement operations.\n","\n","A non-linear generative planner relies on the closed world assumption.\n","\n","**Least commitment planning**: never impose more restrictions than the strictly necessary. This avoids making decisions when they're not required and avoids many backtracking since if a wrong decision is made it's necessary to backtrack.\n","\n","A non-linear planner is represented as:\n","* A set of actions (istances of operators);\n","* A not exhaustive set of **orderings** between actions;\n","* A set of **causal links**.\n","\n","The initial plan is empty, with two fake actions:\n","* **Start**: It has **no preconditions**. Its **effects match the initial state**;\n","* **Stop**: It has **no effects**. Its **preconditions match the goal**;\n","* **Ordering**: Start $<$ Stop.\n","\n","At each step either the set of operators or the set of orderings or the set of casual links is increased until all goals are met (so add an action or an order).\n","\n","A **solution** is a set of partially specified and partially ordered operators.\n","To obtain a real plan we must linearize.\n","\n","> **High level algorithm**:\n"," * While the plan is not complete:\n"," 1. Select an actions $\\text{SN}$ that has a precondition non satisfied (**open goal**);\n"," 1. Select an action $\\text{S}$ (new or already in the plan) that has $\\text{C}$ among its effects;\n"," 1. Add the order constraint $\\text{S}<\\text{SN}$;\n"," 1. If $\\text{S}$ is a new action add the costraint $\\text{Start}<\\text{S}<\\text{Stop}$;\n"," 1. Add the casual link $\\langle\\text{S},\\text{SN},\\text{C}\\rangle$ (the plans are interacting with each other);\n"," 1. Solve any threat on causal links;\n"," * End\n","\n","# Causal links and threats\n","In case of failure, if a choice point exists the algorithm backtracks and explores alternatives.\n"," * A **causal link** is a triple (datastructure) that consists of two operators $S_i$, $S_j$ and a subgoal $C$. $C$ should be precondition of $S_j$ and effect of $S_i$, so $S_i \\overset{c}{\\to} S_j$;\n"," * A causal link stores the causal relationship between actions and helps tackling the problem of interacting goals.\n","\n","An action $\\text{S3}$ is a **threat** for a causal link $\\langle\\text{S1},\\text{S2},\\text{C}\\rangle$ if it has an effect that negates $c$ and no ordering constraint exists that prevent $\\text{S3}$ to be perfomed between $\\text{S1}$ and $\\text{S2}$. \n","Solutions can be:\n","* **Demotion**: the constraint $\\text{S3}<\\text{S1}$ is imposed;\n","* **Promotion**: the constraint $\\text{S2}<\\text{S3}$ is imposed.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tmHwj_2ML7yZ"},"source":["# Partial order planning algorithm (POP)\n","> function `POP(InitialGoal, Operators)` return `plan`:\n"," * `plan` $:=$ `InitialPlan(Start, Stop, InitialGoal)`;\n"," * Loop:\n"," 1. If `Solution(plan)` then return `plan`;\n"," 1. $\\text{SN}$, $\\text{C}$ $:=$ `SelectSubgoal(plan)`;\n"," 1. `ChooseOperator(plan, Operators, SN, C)`;\n"," 1. `ResolveThreats(plan)`;\n"," * End.\n","\n"," > function `SelectSubgoal(plan)` return $\\text{SN}$, $\\text{C}$:\n"," * Select $\\text{SN}$ from `Steps(plan)` with unsolved precondition $\\text{C}$:\n","\n"," > procedure `ChooseOperator(plan, Operators, SN, C)`:\n"," * Pick an $\\text{S}$ with effect $\\text{C}$ from $\\text{Operators}$ or from `Steps(plan)`;\n"," * If $\\text{S}$ doesn't exist then return a `fail`;\n"," * Add the causal link $\\langle\\text{S},\\text{SN},\\text{C}\\rangle$;\n"," * Add the ordering constraint $\\text{S}<\\text{SN}$;\n"," * If $\\text{S}$ is a new action added to the plan then add $\\text{S}$ to `Steps(plan)` and add the constraint $\\text{Start}<\\text{S}<\\text{Stop}$.\n","\n"," > procedure `ResolveThreats(Plan)`:\n"," * for each action $\\text{S}$ that threats a causal links between $S_i$ and $S_j$, choose either:\n"," * Demotion: add the constraint $S<S_i$;\n"," * Promotion: add the constraint $S_j<S$;\n"," * If `NotConsistent(plan)` then reutrn a `fail`"]},{"cell_type":"markdown","metadata":{"id":"Gh7zRvgSbiEg"},"source":[" # Modal Truth Criterion (MTC)\n","As we have seen before, we have to protect every casual link with a proper ordering.\n","A partial order planning algorithm interleaves goal achievement steps with threat protection steps.\n","*Promotion* and *demotion* alone are not enough to ensure **completeness** (a complete planner always finds a solution if it exists).\n","The **Modal Truth Criterion** is a construction process that guarantees planner's completeness.\n","It provieds five operators to move into the space of *plan refinement*:\n","* **Establishment**: open goal achievement through:\n","> 1. A new action to be inserted;\n","  1. An ordering constraint with action already in the plan;\n","  1. A variable assigment (i.e. unification).\n","\n","* **Promotion**: ordering constraint that imposes the threatening action **before** the causal link;\n","* **Demotion**: ordering constraint that imposes the threatening action **after** the causal link;\n","* **White knight**: used when I can't solve a threat with ordering. Insert a new operator or use one already in the plan between $S$ and $SN$ such that it **re-establishes** the precondition of $SN$ thretened by $S$ (reimpose the prencondition);\n","* **Separation**: insert *non codesignation* constraints between the variables of the negative effect and the threatened precondition so to avoid unification. Rarely used.\n","\n","It's always preferable apply promotion and demotion in order to keep the number of the action limited.\n","Non-linear planner tends to generate very innefficient plans, even if correct.\n","\n","Planning is **semi-decidable**: if there's a plan that solves a problem the planner finds it, but if there's not, the planner can work indefinitely.\n"]},{"cell_type":"markdown","metadata":{"id":"5sx5-otCfRUQ"},"source":["# Hierarchical planning\n","Hierarchical planners are search algorithms that manage the creation of complex plans at **different levels of abstraction**, by considering the simplest details only after finding a solution for the most difficult ones.\n","\n","Given a goal, the hierarchical planner performs a **meta-level search** to generate a **meta-level plan** which leads *from a state that is very close to the initial one to a state which is very close to the goal*.\n","The plan is then completed with a lower level search, taking account of details omitted at the previous level.\n","\n","Hierarchical algorithm must be able to:\n","* Organize well the meta-levels;\n","* Expand abstract plans into concrete plans (planning abstract parts in terms of more specific actions and then expanding already prebuilt plans).\n","\n","Note: at each level of the meta-search we may use different algorithms such as STRIPS or POP.\n","\n","# ABSTRIPS\n","At every level of abstraction we consider only some preconditions with a threshold (**criticality value**), proportional to the complexity of its goal.\n","The algorithm proceeds at different levels of abstraction spaces, refines changing the threshold.\n","At each level, lower level preconditions are ignored.\n","\n","ABSTRIPS fully explores the space of a certain level of abstracion before moving on to a more detailed level (lenght search).\n","\n","> **Algorithm**:\n","1. A thresold values is fixed;\n","1. All preconditions whose criticality is lower than the treshold are considered true;\n","1. STRIPS (or else, at each level we may use different planners) finds a plan that meets all the considered preconditions;\n","1. Then uses the full plan pattern obtained as a guide and lower the value of the threshold;\n","1. It extends the plan with operators that meet the new preconditions;\n","1. Again, lowers the threshold until all the preconditions are considered.\n","\n","# Macro-operators\n","We have two kinds of operators:\n","* **Atomic operators**: represents elementary actions that can be directly performed by an agent;\n","* **Macro operators**: represents a set of elementary actions decomposable into atomic operators. \n","\n","Before execution they should be decomposed and it's possible to *precompile it* or *plan it*:\n","* **Pre-compiled decomposition**: the description of the macro operator also contains the *decomposition*, that is the sequence of basic operators to be executed at run-time;\n","* **Planned decomposition**: the planner must perform a low-level search for synthesizing the atomic action plan that implement the macro action.\n","\n","The planning algorithm can be either linear or non-linear.\n","A hierarchical non-linear algorithm is similar to POP where at each step one can choose between:\n","* Reach an open goal with an operator (either atomic or macro);\n","* Expand a macro step of the plan (decomposition can be either precompiled or planned)\n","\n","> function `HD_POP(InitialGoal, methods, operators)` return `plan`\n","* `plan` $\\leftarrow$ `InitialPlan(Start, Stop, InitialGoal)`;\n","* Loop:\n","1. If `Solution(plan)` then return `plan`;\n","1. Else, choose between:\n","* $SN$, $C$ $\\leftarrow$ `SelectSubgoal(plan)`;\n","* `ChooseOperator(plan, operators, SN, C)`.\n","2. Or:\n","* SnonPrim $C$ $\\leftarrow$ `SelectMacroStep(plan)`;\n","* `ChooseDecomposition(SononPrim, methods, plan)`.\n","3. `SolveThreats(plan)`.\n","\n","# Decomposition\n","To ensure decomposition is safe, some properties must be guaranteed.\n","If the macro action $A$ has the effect $X$ and is expanded with the plan $P$:\n","1. $X$ must be the effect of at least on of the actions in which $A$ is decomposed and should be protected until the end of the plan $P$;\n","1. Each precondition of the actions in $P$ must be guaranteed by the previous actions in $P$ or it must be a precondition of $A$;\n","1. The action $P$ must not threat any causal link when $P$ is substituted for $A$ in the plan.\n","\n","Under these conditions you can replace the macro action $A$ with the plan $P$. When replacing, orderings and causal links should be added:\n","1. **Orderings**\n","* For each $B$ such that $B<A$, then $B<\\text{first}(P)$ is imposed (first action of $P$);\n","* For each $B$ such that $A<B$, then $\\text{last}(P)<B$ is imposed (last action of $P$);\n","\n","2. **Causal links**\n","* If $\\langle S,A,C \\rangle$ is a causal link in the initial plan, then it must be replaced by a set of causal links $\\langle S,S_i,C \\rangle$, where $S_i$ are the action of $P$ that have $C$ as a precondition and no other step fo $A$ before it has a $C$ as a precondition;\n","* If $\\langle A,S,C \\rangle$ is a causal link in the initial plan, then it must be replaced by a set of causal links $\\langle S_i,S,C \\rangle$, where $S_i$ are the action of $P$ that have $C$ as a action and no other step fo $P$ after it has the effect $C$."]},{"cell_type":"markdown","metadata":{"id":"sgDACpPHvMA8"},"source":["# Execution\n","Generative planners build plans that are then executed by an executing agents.\n","There may be different problems, such as:\n","* An action should be executed but its preconditions are not satisfied, due to **incomplete/incorrect knowledge**, **unexpected conditions**, relaxation of the **close world assumption**;\n","* Action effects are not the one expected, due to **error of the agents** or **non-deterministic effects**.\n","\n","While executing, the agent should *perceive* the changes in the world and acting accordingly, using sensors to change the description of the world.\n","\n","Some planners run under the **open world assumption**, where the information that aren't explicitly stated in a state isn't false but **unknown**.\n","The unknown information can be retrieved via **sensing actions** added to the plan, modeled as causals actions:\n","* Preconditions are conditions that must be true to perform a certain observation;\n","* Postconditions are the result of the observation.\n","\n","There are two possible aproaches: integration between planning and execution or **conditional planning**.\n"]},{"cell_type":"markdown","metadata":{"id":"mzCkaSwE9ACT"},"source":["# Conditional planning\n","A conditional planner is a search algorithm that generates various alternative plans for each source of uncertainty of the plan.\n","It's constitued by:\n","* Causal actions;\n","* Sensing actions;\n","* Several alternative partial plans of which only one will be executed depending on the results of the observations.\n","\n","This process is extremely high demanding, it causes an **explosion** of the search tree. \n","A comprehensive plan which takes account of every possible contingency might require a lot of memory since not always all alternatives are known in advance.\n","\n","Often conditional planners are associated with probabilistic planners that plan only for the most probable contest. They're called **contingiency planner**. "]},{"cell_type":"markdown","metadata":{"id":"jzRJsgSK840_"},"source":["# Reactive planning\n","Reactive planners are non-generative online algorithms, capable of interacting with the world and dealing with **dynamicity** and **non-determinism**. They:\n","* Observe the world in the planning state;\n","* Acquire unknown information;\n","* Monitor the implementation of actions and check the effects;\n","* Interleave planning and execution.\n","\n","Pure reactive planners do not plan but react as triggers to world variations (closer to control systems, but based on rules).\n","They have access to a knowledge base that describes what actions must be carried out and under what circumstances.\n","They choose one action at a time without any lookahead activicy.\n","\n","* **Pros**:\n","1. Able to interact with the real system. Robust in domains for which it's difficult to provide complete and accurate models;\n","1. Don't use models but perceive changes. Extremely fast responses.\n","* **Cons**:\n","1. Their perfomance in predictable domains is low.\n","\n","# Hybrid systems\n","Modern responsive planners are **hybrids**.\n","Integrate **generative** and **reactive** approaches in order to exploit the computational capacity of the first and the ability to interact with the system of the second thus addredding the problem of execution.\n","They:\n","* Generates a plan to achieve the goal (offline);\n","* Checks the preconditions of the action that is about to run and the effects of the previously executed action;\n","* Backtracks the effects and reschedules in case of failures (if possible, some actions aren't backtrackable);\n","* **Correct the plan if unforeseen event occour**."]}]}