{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_informed_search_strategies.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMggFpmqDcKFM5D4pJ5XgUJ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NAk4JMgVNiia"},"source":["# **Informed search strategies**\n","Intelligence of systems can't be measured in terms of search capability (*intelligence is not speed*), but in the ability to **use the knowledge to mitigate the combinatorial explosion**.\n","If the system has some control on the order in which possible solutions are generated then it can be useful to use this order so that solutions have a high chances to appear before.\n","\n","**Idea**: resort, using heuristic domain knowledge, to decide which node to expand first.\n","\n","The evaluation functions give a computational estimate (not exactly known, otherwise we wouldn't need search) of the effort to reach the final state.\n","The time spent to evaluate a node with an heuristic should correspond to a reduction in the size of the space explored.\n","There is a trade-off between:\n","* The time it takes to solve the problem (baseline);\n","* The time spent in reasoning (meta-level).\n","\n","It can be difficult to numerically characterize the empirical knowledge about the problem and choose the correct evaluation function.\n"]},{"cell_type":"markdown","metadata":{"id":"FLXPodCBjeK8"},"source":["# Best-first search\n","> Best first search uses evaluation functions tha compute a number that represents the **desiderability of the node expansion**. The choosen node is the one considered as the most desiderable.\n","\n","The queue is formed inserting successors in *descending order of desiderability*.\n","The idea is to move toward the maximum (or minimum) of a function that estimates the desiderability (or the cost) to reach the goal."]},{"cell_type":"markdown","metadata":{"id":"W4UacfEFSm-w"},"source":["# A) Greedy search algorithm\n","> **Greedy search** (hill climbing):\n","1. Let $L$ be a list of the initial nodes of the problem, ranked according to their distance from the goal in ascending order (nearest solution are more desirable);\n","1. If $L$ is empty the it's a fail;\n","1. Else, let be $n$ the first node of $L$. If $n$ is the goal return a solution;\n","1. Otherwise, remove $n$ from the list and add his children;\n","1. Then resort $L$ and repeat from step 2.\n","\n","We can also see this as a general search algorithm that uses an evaluation function to generate the queue.\n","\n","The best-search algorithm is **not optimal** in the sense that is not guaranteed to find the best solution nor the best path since it tries to find as soon as possible a node with 0 zero distance from the goal and not the one with the lower depth. It may also be **incomplete**.\n","In the worst case space and time complexity can be $\\mathcal{O}(b^d)$ since it has to mantain the fringe in memory.\n","Although, with a good heursitc function, both complexities can be reduce substantially."]},{"cell_type":"markdown","metadata":{"id":"X72w-em6jZdX"},"source":["# B) A* algorithm\n","Instead of only considering the distance to the goal we also consider the cost in reaching the node $n$ from the root.\n","We expand nodes for increasing values of $f(n)=g(n)+h'(n)$, where:\n","* $g(n)$ is the depth of the node;\n","* $h'(n)$ is the estimated distance from the goal.\n","\n","So we choose the node to expand with the smaller minimum cost $f(n)$.\n","If we have a tie we can choose randomly or use another heuristic for that node to break the tie.\n","\n","The A* algorithm is **optimal** and **complete**, combines benefits from depth-first search (efficiency) with the ones of uniform cost search (optimality and completeness). It's able to **avoid loops** since $g$ always increases.\n","> **A* algorithm**:\n","1. Let $L$ be a list of the initial nodes of the problem;\n","1. If $L$ is empty the it's a fail;\n","1. Else, let be $n$ the node for which $f(n)$ is minimal. If $n$ is the goal return a solution;\n","1. Otherwise, remove $n$ from the list and add his children, labeled with $f(n)$;\n","1. Repeat from step 2.\n","\n","The algorithm doesn't guarantee in general to find an optimal solution, it depends on the heuristic used. \n","Suppose that $h(n)$ is the true distance between the current node and the goal and $h'(n)$ is the heuristic function used in the algorithm. \n","The heuristic $h'(n)$ is **optimistic** if it's always $h'(n)\\le h(n)$, therefore the function **always understimate the real heuristic** and so it's said to be **feasible**.\n","> **Theorem**: if $h'(n)$ is feasible for each node then A* algorithm always finds the optimal path to the goal.\n","\n","**Eligible heuristic functions**: We can define different heuristics. \n","It's better to use a heuristic function with higher values (if it's optimistic), so $h'(n)=\\max(h_1(n),h_2(n),\\dots,h_m(n))$.\n","Often, the cost of an exact solution of a relaxed problem is a good heuristic for the original problem.\n"]},{"cell_type":"markdown","metadata":{"id":"Mu17AFWzmPPR"},"source":["# Graph-search\n","We assumed so far that the search space is a tree (each node has only one parent) rather than a graph.\n","Therefore, it's not possible to achieve the same node from different path.\n","This assumption is of course semplicistic.\n","\n","> `Graph-search(problem,fringe)`:\n","1. `closed` <- empty set;\n","1. `fringe` <- initial state;\n","1. If the fringe is empty return a **failure**;\n","1. `node` <- takes and remove the first node of the fringe;\n","1. If the `node` is the goal then return a **solution**;\n","1. If the `node` isn't in `closed` then add it and insert in the `fringe` the expansion of that node;\n","1. Repeat from step 3.\n","\n","In this case we have two list:\n","* **Closed nodes**: expanded nodes that are removed from the list to avoid further examination;\n","* **Open nodes (fringe)**: nodes still to be examined.\n","\n","Everytime that I find a node that I have already explored it means that there's another patho to reach that node (that may be shorter).\n","\n","# A* algorithm for graph-search\n","In this case the graph can become a tree with repeated nodes, the list of closed nodes is added and assumed that $g(n)$ evaluates the minimum distance of the node $n$ from the starting node.\n","> **A* algorithm for graph**:\n","1. Let $L_a$ be the open list of the initial nodes of the problem;\n","1. Let be $n$ the node for which $f(n)$ is minimal. If $L_a$ is empty then return a **failure**;\n","1. If $n$ is the goal then stop and return the path to reach it.;\n","1. Otherwise, remove $n$ from the $L_a$, put it in the list of closed node $L_c$ and add to $L_a$ all children of $n$, labelling them with the cost from the starting node to $n$\n","1. If a child node is already in $L_a$ don't add it again but update it's label in case the cost is smaller;\n","1. If a child node is already in $L_c$ don't add it in $L_a$, but if it's cost is better update its cost and the one of its children and descendant;\n","1. Repeat from step 2.\n","\n","For graph-search there's another condition: **consistency**.\n","> A heuristic is **consistent** if for each node $n$, any successor $n'$ of $n$, generated by each action $a$:\n","* $h(n)=0$ if the corresponding status is the goal;\n","* $h(n)\\le c(n,a,n')+h(n')$ otherwise.\n","\n","With monotonicity we are guaranteed to find the shortest path from the root to the goal, so A* for graph-search will be **optimal**."]}]}